---
title: "Darwin Core mapping"
subtitle: "For: Muskrat occurrences Flanders"
author:

- Dimitri Brosens
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    number_sections: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
#  pdf_document:
#    df_print: kable
#    number_sections: yes
#    toc: yes
#    toc_depth: 3
---

# Setup 

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = TRUE)
```

Load libraries:

```{r message = FALSE}
library(tidyverse)      # To do data science
library(tidylog)        # To provide feedback on dplyr functions
library(magrittr)       # To use %<>% pipes
library(here)           # To find files
library(janitor)        # To clean input data
library(readxl)         # To read Excel files
library(digest)         # To generate hashes
library(rgbif)          # To use GBIF services
```

# Read source data

Create a data frame `input_data` from the source data:

```{r}

input_data <- read_csv(file = here("data", "raw", "AgrDataGBIF.csv")) 
#input_data <- read_csv("../data/raw/AgrDataGBIF.csv")

```

Preview data:

```{r}
input_data %>% head(n = 5)
```

# Process source data

## Tidy data

Clean data somewhat:

```{r}
input_data %<>% remove_empty("rows")
```

## Scientific names
(kolom toevoegen)

```{r}
input_data %<>% mutate(kingdom = "Animalia") %>%
                mutate(scientificName = "Ondatra zibethicus") %>%
                paste0("Please delete this col! ", input_data$X1)


```

Rename column scientificName (we don't want multiple times the same column header)

```{r}
input_data %<>% 
  rename(verbatimScientificName = scientificName)
```


Use the [GBIF nameparser](https://www.gbif.org/tools/name-parser) to retrieve nomenclatural information for the scientific names in the dataset:

```{r}
parsed_names <- input_data %>%
  distinct(verbatimScientificName) %>%
  pull() %>% # Create vector from dataframe
  parsenames() # An rgbif function
```

Preview data:

```{r}
parsed_names %>% head(n = 62)
```

Show scientific names with nomenclatural issues, i.e. not of `type = SCIENTIFIC` or that could not be fully parsed. Note: these are not necessarily incorrect.

```{r}
parsed_names %>%
  select(scientificname, type, parsed, parsedpartially, rankmarker) %>%
  filter(!(type == "SCIENTIFIC" & parsed == "TRUE" & parsedpartially == "FALSE"))
```

Correct names and reparse:

```{r correct and reparse}
input_data %<>% mutate(scientificname = recode(verbatimScientificName,
  "Gibbulinella aff. dealbata" = "Gibbulinella dealbata",
  "Hemicycla cf. gaudryi" = "Hemicycla gaudryi",
  "Xerotricha aff. orbignii" = "Xerotricha orbignii",
  "Napaeus cf. venegueraensis" = "Napaeus venegueraensis",
  "Monilearia cf. praeposita" = "Monilearia praeposita",
  "Gibbulinella aff. dewinteri" = "Gibbulinella dewinteri",
  "Pomatias aff. laevigatus" = "Pomatias laevigatus",
  "Physella cf. acuta" = "Physella acuta",
  "Hemicycla psathyra cf. temperata" = "Hemicycla psathyra temperata"
))
```


```{r correct and reparse}
# Redo parsing
parsed_names <- input_data %>%
  distinct(scientificname) %>%
  pull() %>%
  parsenames()
```


# Show names with nomenclatural issues again

```{r correct and reparse}
parsed_names %>%
  select(scientificname, type, parsed, parsedpartially, rankmarker) %>%
  filter(!(type == "SCIENTIFIC" & parsed == "TRUE" & parsedpartially == "FALSE"))
```

## Taxon ranks

The nameparser function also provides information about the rank of the taxon (in `rankmarker`). Here we join this information with our checklist. Cleaning these ranks will done in the Taxon Core mapping:


```{r}
input_data %<>% left_join(
  parsed_names %>%
  select (scientificname, rankmarker),
  by = c("scientificname" = "scientificname"))
```

```{r}
# Adjust rankmarker
input_data %<>% mutate(rankmarker = recode(verbatimScientificName,
  "Monilearia spec." = "genus",
  "Hemicycla spec." = "genus",
  "Napaeus spec." = "genus",
  .default = rankmarker
))
```

## Taxon IDs

To link taxa with information in the extension(s), each taxon needs a unique and relatively stable `taxonID`. Here we create one in the form of `dataset_shortname:taxon:hash`, where `hash` is unique code based on scientific name and kingdom (that will remain the same as long as scientific name and kingdom remain the same):

```{r}
vdigest <- Vectorize(digest) # Vectorize digest function to work with vectors
input_data %<>% mutate(taxon_id = paste(
  "muskrat-occurrences", # e.g. "alien-fishes-checklist"
  "taxon",
  vdigest(paste(verbatimScientificName, kingdom), algo = "md5"),
  sep = ":"
))
```

## Preview data

Show the number of taxa and distributions per kingdom and rank:

```{r}
input_data %>%
  group_by(kingdom, rankmarker) %>%
  summarize(
    `# taxa` = n_distinct(taxon_id),
    `# distributions` = n()
  ) %>%
  adorn_totals("row")
```

Preview data:

```{r}
View(input_data)
```

# Occurrence core

## Pre-processing

Create a dataframe occurrence data only (ignoring multiple distribution rows):

```{r}
occurrence <- input_data
```

## Term mapping

Map the data to [Darwin Core Occurrence](http://rs.gbif.org/core/dwc_occurrence_2015-07-02.xml).

Start with record-level terms which contain metadata about the dataset (which is generally the same for all records).

### language

```{r}
occurrence %<>% mutate(language = "en") # e.g. "en"
```

### license

```{r}
occurrence %<>% mutate(license = "http://creativecommons.org/publicdomain/zero/1.0/") 
# e.g. "http://creativecommons.org/publicdomain/zero/1.0/"
```

### rightsHolder

```{r}
occurrence %<>% mutate(rightsHolder = "INBO") # e.g. "INBO"
```

### datasetID

```{r}
occurrence %<>% mutate(datasetID = "https://doi.org/10.15468/ny1f9n") # e.g. "https://doi.org/10.15468/xvuzfh"
```

### institutionCode

```{r}
occurrence %<>% mutate(institutionCode = "UGent") # e.g. "INBO"
```

### datasetName

```{r}
occurrence %<>% mutate(datasetName = "Land and freshwater molluscs of Gran Canaria (Spain)") # e.g. "Checklist of non-native freshwater fishes in Flanders, Belgium"
```

The following terms contain information about the taxon:

### taxonID

```{r}
#occurrence %<>% mutate(taxonID = taxon_id)
#Better: rename old column
occurrence %<>% rename(taxonID = taxon_id)
```

### scientificName + (intra)specificEpithet

```{r}
occurrence %<>% rename(scientificName = scientificname)
occurrence %<>% rename(specificEpithet = species)
occurrence %<>% rename(infraspecificEpithet = subspecies)
```
### scientificNameAuthorship

```{r}
occurrence %<>% rename(scientificNameAuthorship = author)
```

###identifiedBy
rename column determinavit(det.)

```{r}
occurrence %<>% rename(identifiedBy = 'determinavit (det.)')
```



### kingdom

Inspect values:

```{r}
occurrence %>%
  group_by(kingdom) %>%
  count()
```

Map values:


### taxonRank

Inspect values:

```{r}
occurrence %>%
  group_by(rankmarker) %>%
  count()
```

Map values by recoding to the [GBIF rank vocabulary](http://rs.gbif.org/vocabulary/gbif/rank_2015-04-24.xml):

```{r}
occurrence %<>% mutate(taxonRank = recode(rankmarker,
  "infrasp."  = "subspecies",
  "sp."       = "species",
  "var."      = "variety",
  "f."        = "form",
  "genus"     = "genus",
  "subgenus"  = "subgenus",
  "family"    = "family",
  "class"     = "class",
  .default    = "",
  .missing    = ""
))
```

Inspect mapped values: 

```{r}
occurrence %>%
  group_by(rankmarker, taxonRank) %>%
  count()
occurrence %<>% select(-rankmarker)
```

### nomenclaturalCode

```{r}
occurrence %<>% mutate(nomenclaturalCode = "ICZN") # e.g. "ICZN"
```

## Post-processing


```{r}
colnames(occurrence) <- str_remove(colnames(occurrence), "dwc_")

occurrence %<>% select(-c(disposition, etiket_ref, collection, scientificName)) %<>% #remove collection columns
            rename(scientificName = verbatimScientificName) 

```

Preview data:

```{r}
occurrence %>% head()
View(occurrence)
```

Save to CSV:

```{r}
#write_csv(occurrence, here("data", "processed", "occurrence.csv"), na = "")
#write_csv(occurrence, here("data", "processed", "occurrence.csv"), append = FALSE, na = "")
write.csv(occurrence, "../data/processed/occurrence.csv", append = FALSE, na = "",  row.names = FALSE, fileEncoding = "UTF-8")
```

